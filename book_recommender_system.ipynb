{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234494c4-919a-48ce-accf-9c0dfec57415",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b69cf4-50ed-4bef-8813-e43e714b3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30051c9-ac18-41ff-8a27-0bc907b390be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of books dataset\n",
      "         ISBN                                         Book-Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            Book-Author Year-Of-Publication                   Publisher  \\\n",
      "0    Mark P. O. Morford                2002     Oxford University Press   \n",
      "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este                1991             HarperPerennial   \n",
      "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                         Image-URL-S  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "First 5 rows of users dataset\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "First 5 rows of ratings dataset\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n"
     ]
    }
   ],
   "source": [
    "# Get the directory of each dataset \n",
    "path = os.path.dirname(os.path.abspath(\"Books.csv\"))\n",
    "book_path = path + \"/datasets/Books.csv\"\n",
    "users_path = path + \"/datasets/Users.csv\"\n",
    "ratings_path = path + \"/datasets/Ratings.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "books_dataset = pd.read_csv(book_path, low_memory=False)\n",
    "users_dataset = pd.read_csv(users_path, low_memory=False)\n",
    "ratings_dataset = pd.read_csv(ratings_path, low_memory=False)\n",
    "\n",
    "# Print the first 5 rows of each dataset \n",
    "print(\"First 5 rows of books dataset\")\n",
    "print(books_dataset.head(5))\n",
    "\n",
    "print(\"First 5 rows of users dataset\")\n",
    "print(users_dataset.head(5))\n",
    "\n",
    "print(\"First 5 rows of ratings dataset\")\n",
    "print(ratings_dataset.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafe5802-fc02-4c87-9ff8-c15eb17080a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Dataset Summary: \n",
      "              ISBN      Book-Title      Book-Author Year-Of-Publication  \\\n",
      "count       271360          271360           271358              271360   \n",
      "unique      271360          242135           102022                 118   \n",
      "top     020130998X  Selected Poems  Agatha Christie                2002   \n",
      "freq             1              27              632               17627   \n",
      "\n",
      "        Publisher                                        Image-URL-S  \\\n",
      "count      271358                                             271360   \n",
      "unique      16807                                             271044   \n",
      "top     Harlequin  http://images.amazon.com/images/P/155936078X.0...   \n",
      "freq         7535                                                  2   \n",
      "\n",
      "                                              Image-URL-M  \\\n",
      "count                                              271360   \n",
      "unique                                             271044   \n",
      "top     http://images.amazon.com/images/P/155936078X.0...   \n",
      "freq                                                    2   \n",
      "\n",
      "                                              Image-URL-L  \n",
      "count                                              271357  \n",
      "unique                                             271041  \n",
      "top     http://images.amazon.com/images/P/155936078X.0...  \n",
      "freq                                                    2  \n",
      "-----------------------\n",
      "Users Dataset Summary: \n",
      "            User-ID            Age\n",
      "count  278858.00000  168096.000000\n",
      "mean   139429.50000      34.751434\n",
      "std     80499.51502      14.428097\n",
      "min         1.00000       0.000000\n",
      "25%     69715.25000      24.000000\n",
      "50%    139429.50000      32.000000\n",
      "75%    209143.75000      44.000000\n",
      "max    278858.00000     244.000000\n",
      "-----------------------\n",
      "Ratings Dataset Summary:\n",
      "            User-ID   Book-Rating\n",
      "count  1.149780e+06  1.149780e+06\n",
      "mean   1.403864e+05  2.866950e+00\n",
      "std    8.056228e+04  3.854184e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the statistical summary for each dataset\n",
    "print(\"Books Dataset Summary: \")\n",
    "print(books_dataset.describe())\n",
    "print(\"-----------------------\")\n",
    "\n",
    "print(\"Users Dataset Summary: \")\n",
    "print(users_dataset.describe())\n",
    "print(\"-----------------------\")\n",
    "\n",
    "print(\"Ratings Dataset Summary:\")\n",
    "print(ratings_dataset.describe())\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b12e57-c97d-4ad9-8dba-056972a93400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in merged dataset: \n",
      "User-ID             0\n",
      "Location            0\n",
      "Age            309492\n",
      "ISBN                0\n",
      "Book-Rating         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in books dataset: \n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge the ratings and users dataset together based on ID\n",
    "merged_data = users_dataset.merge(ratings_dataset, on='User-ID')\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "missing_merged = merged_data.isnull().sum()\n",
    "missing_books = books_dataset.isnull().sum()\n",
    "print(\"Missing values in merged dataset: \")\n",
    "print(missing_merged, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Missing values in books dataset: \")\n",
    "print(missing_books)\n",
    "\n",
    "# Remove the rows where Book-Author and Publisher are null\n",
    "books_dataset.dropna(subset=['Book-Author', 'Publisher'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801fb38-2377-48c1-b54a-4403b7ee4134",
   "metadata": {},
   "source": [
    "# Split the Data and Get Some Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3326eef2-71ad-454a-95d0-200793ea500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean: 2.8676801214145313 \n",
      "\n",
      "User Mean:\n",
      " User-ID\n",
      "7          0.000000\n",
      "8          2.090909\n",
      "9          2.000000\n",
      "10         3.000000\n",
      "12        10.000000\n",
      "            ...    \n",
      "278846     4.000000\n",
      "278849     2.250000\n",
      "278851     3.857143\n",
      "278852     8.000000\n",
      "278854     4.833333\n",
      "Name: Book-Rating, Length: 92906, dtype: float64 \n",
      "\n",
      "Item Mean:\n",
      " ISBN\n",
      " 0330299891    3.0\n",
      " 0586045007    0.0\n",
      " 9022906116    3.5\n",
      " 9032803328    0.0\n",
      " 9044922572    0.0\n",
      "              ... \n",
      "cn113107       0.0\n",
      "ooo7156103     7.0\n",
      "§423350229     0.0\n",
      "´3499128624    8.0\n",
      "Ô½crosoft      7.0\n",
      "Name: Book-Rating, Length: 298432, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate global mean rating, user mean rating and item mean rating\n",
    "global_mean = train_data['Book-Rating'].mean()\n",
    "user_means = train_data.groupby('User-ID')['Book-Rating'].mean()\n",
    "item_means = train_data.groupby('ISBN')['Book-Rating'].mean()\n",
    "\n",
    "# Print the means\n",
    "print(\"Global Mean:\", global_mean,\"\\n\")\n",
    "print(\"User Mean:\\n\",user_means,\"\\n\")\n",
    "print(\"Item Mean:\\n\",item_means,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae12279-8b7d-4c58-8bb4-0f86b0541bbe",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe32ea98-c519-47dc-b7b9-6e80f9f36754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering(user_id, item_id, user_item_matrix, k=5):\n",
    "    if user_id not in user_item_matrix.index or item_id not in user_item_matrix.columns:\n",
    "        return global_mean\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    similar_users = user_item_matrix.corrwith(user_ratings).dropna().sort_values(ascending=False)[1:k+1]\n",
    "    similar_users_ratings = user_item_matrix.loc[similar_users.index, item_id]\n",
    "    return similar_users_ratings.mean() if not similar_users_ratings.empty else global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce68091-c561-4480-916e-697f0996b6b0",
   "metadata": {},
   "source": [
    "# Hybrid Weighted Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97de3cc9-c9eb-4ddb-8486-4c51e79addc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommender(user_id, item_id, user_means, item_means, user_item_matrix, weights=(0.3, 0.3, 0.4)):\n",
    "    global_pred = global_mean\n",
    "    user_pred = user_means.get(user_id, global_mean)\n",
    "    item_pred = item_means.get(item_id, global_mean)\n",
    "    cf_pred = collaborative_filtering(user_id, item_id, user_item_matrix)\n",
    "\n",
    "    # Weighted sum\n",
    "    final_pred = (weights[0] * global_pred + weights[1] * user_pred + weights[2] * item_pred + (1 - sum(weights)) * cf_pred)\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c231d-893b-4559-8dc4-58e02174fd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
